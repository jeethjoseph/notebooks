{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what Popularity recommendation does\n",
    "\n",
    "## 1. Import modules\n",
    "* `pandas` and `numpy` for data manipulation\n",
    "* `turicreate` for performing model selection and evaluation\n",
    "* `sklearn` for splitting the data into train and test set\n",
    "* `xlrd` for excel import\n",
    "* sudo apt-get install libatlas-base-dev for missing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import turicreate as tc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import scripts.data_layer as data_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "Single dataset from db, which can be found in `data` folder: \n",
    "* Lyb data QUEST JAN WITH PURQTY 10k (to avoid memory error)\n",
    "* XLSX Format\n",
    "* Possible error expected dude to difference between expected purchase frequency and purchase qty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s=time.time()\n",
    "\n",
    "data=pd.read_excel('../data/Lyb data QUEST JAN WITH PURQTY 10k.xlsx')\n",
    "\n",
    "print(\"Import time:\", round((time.time()-s)/60,2), \"minutes\")\n",
    "\n",
    "print(data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split train and test set\n",
    "* Splitting the data into training and testing sets is an important part of evaluating predictive modeling, in this case a collaborative filtering model. Typically, we use a larger portion of the data for training and a smaller portion for testing. \n",
    "* We use 80:20 ratio for our train-test set size.\n",
    "* Our training portion will be used to develop a predictive model, while the other to evaluate the model's performance.\n",
    "* Now that we have three datasets with purchase counts, purchase dummy, and scaled purchase counts, we would like to split each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = .2)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using turicreate library, we convert dataframe to SFrame - this will be useful in the modeling part\n",
    "\n",
    "train_data = tc.SFrame(train)\n",
    "test_data = tc.SFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Baseline Model\n",
    "Before running a more complicated approach such as collaborative filtering, we would like to use a baseline model to compare and evaluate models. Since baseline typically uses a very simple approach, techniques used beyond this approach should be chosen if they show relatively better accuracy and complexity.\n",
    "\n",
    "### 5.1. Using a Popularity model as a baseline\n",
    "* The popularity model takes the most popular items for recommendation. These items are products with the highest number of sells across customers.\n",
    "* We use `turicreate` library for running and evaluating both baseline and collaborative filtering models below\n",
    "* Training data is used for model selection\n",
    "* Yet to evaluate is the math behind turicerate.popularity model\n",
    "\n",
    "#### Using purchase counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to define field names\n",
    "user_id = 'LYBID'\n",
    "item_id = 'ITEMID'\n",
    "target = 'TotalQtyPurchased'\n",
    "users_to_recommend = list(data[user_id].unique())\n",
    "n_rec = 5 # number of items to recommend\n",
    "n_display = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_model = tc.popularity_recommender.create(train_data, \n",
    "                                                    user_id=user_id, \n",
    "                                                    item_id=item_id, \n",
    "                                                    target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommendations for a list of users to recommend (from data file)\n",
    "# Printed below is head / top 30 rows for first 6 customers with 5 recommendations each\n",
    "\n",
    "popularity_recomm = popularity_model.recommend(users=users_to_recommend, k=n_rec)\n",
    "popularity_recomm.print_rows(n_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
